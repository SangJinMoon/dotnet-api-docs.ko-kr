<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="DictationGrammar.xml" source-language="en-US" target-language="ko-KR">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-15c36f0" tool-company="Microsoft" />
      <xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">02cd5861-7ce2-4a82-b358-31f8435a0ac503cbcbf150eedd38688c32681c06070f0170c03d.skl</xliffext:skl_file_name>
      <xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version>
      <xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">03cbcbf150eedd38688c32681c06070f0170c03d</xliffext:ms.openlocfilehash>
      <xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">d31dc2ede16f6f7bc64e90d9f897ff54c4e3869b</xliffext:ms.sourcegitcommit>
      <xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">04/03/2018</xliffext:ms.lasthandoff>
      <xliffext:moniker_ids xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">netframework-4.5.1,netframework-4.5.2,netframework-4.5,netframework-4.6.1,netframework-4.6.2,netframework-4.6,netframework-4.7.1,netframework-4.7</xliffext:moniker_ids>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.DictationGrammar">
          <source>Represents a speech recognition grammar used for free text dictation.</source>
          <target state="translated">자유 텍스트 받아쓰기를 위해 사용하는 스피치 인식 그래머를 표현한다</target>       </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.DictationGrammar">
          <source>This class provides applications with a predefined language model that can process spoken user input into text.</source>
          <target state="translated">이 클래스는 응용 프로그램 텍스트에 대 한 음성된 사용자 입력을 처리할 수 있는 미리 정의 된 언어 모델을 제공 합니다.</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.DictationGrammar">
          <source>This class supports both default and custom <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> objects.</source>
          <target state="translated">이 클래스는 기본 및 사용자 지정 둘 다 지원 <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> 개체입니다.</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.DictationGrammar">
          <source>For information about selecting a dictation grammar, see the <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar.%23ctor%28System.String%29&gt;</ph> constructor.</source>
          <target state="translated">선택 받아쓰기 문법에 대 한 정보를 참조 하십시오.는 <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar.%23ctor%28System.String%29&gt;</ph> 생성자입니다.</target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.DictationGrammar">
          <source>By default, the <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> language model is context free.</source>
          <target state="translated">기본적으로는 <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> 언어 모델에서 사용 가능한 컨텍스트.</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.DictationGrammar">
          <source>It does not make use of specific words or word order to identify and interpret audio input.</source>
          <target state="translated">특정 단어의 사용 하거나 순서를 식별 하 여 오디오 입력 해석 단어 만들지 않습니다.</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.DictationGrammar">
          <source>To add context to the dictation grammar, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A&gt;</ph> method.</source>
          <target state="translated">받아쓰기 문법에 컨텍스트를 추가 하려면 사용 된 <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A&gt;</ph> 메서드.</target>       </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.DictationGrammar">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> objects do not support the <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.Priority%2A&gt;</ph> property.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> 개체는 지원 하지는 <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.Priority%2A&gt;</ph> 속성입니다.</target>       </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.DictationGrammar">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> throws a <ph id="ph2">&lt;xref:System.NotSupportedException&gt;</ph> if <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar.Priority%2A&gt;</ph> is set.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> throw 한 <ph id="ph2">&lt;xref:System.NotSupportedException&gt;</ph> 경우 <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar.Priority%2A&gt;</ph> 설정 됩니다.</target>       </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.DictationGrammar">
          <source>The following example creates three dictation grammars, adds them to a new <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> object, and returns the new object.</source>
          <target state="translated">다음 예제에서는 세 받아쓰기 문법을 만들고, 새에 추가 <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> 개체를 새 개체를 반환 합니다.</target>       </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.DictationGrammar">
          <source>The first grammar is the default dictation grammar.</source>
          <target state="translated">첫 번째 문법 기본 받아쓰기 문법이입니다.</target>       </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.DictationGrammar">
          <source>The second grammar is the spelling dictation grammar.</source>
          <target state="translated">두 번째 문법 맞춤법 받아쓰기 문법이입니다.</target>       </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.DictationGrammar">
          <source>The third grammar is the default dictation grammar that includes a context phrase.</source>
          <target state="translated">세 번째 문법 컨텍스트 구를 포함 하는 기본 받아쓰기 문법이입니다.</target>       </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.DictationGrammar">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A&gt;</ph> method is used to associate the context phrase with the dictation grammar after it is loaded to the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> object.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A&gt;</ph> 메서드에 로드 된 후 상황에 맞는 구 받아쓰기 문법을 연결할 때 사용 되는 <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> 개체입니다.</target>       </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.DictationGrammar">
          <source>Initializes a new instance of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.DictationGrammar" /&gt;</ph> class.</source>
          <target state="translated"><ph id="ph1">&lt;see cref="T:System.Speech.Recognition.DictationGrammar" /&gt;</ph> 클래스의 새 인스턴스를 초기화합니다.</target>       </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.DictationGrammar.#ctor">
          <source>Initializes a new instance of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.DictationGrammar" /&gt;</ph> class for the default dictation grammar provided by Windows Desktop Speech Technology.</source>
          <target state="translated">Windows 데스크톱 음성 기술을 통해 제공되는 기본 받아쓰기 문법에 대한 <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.DictationGrammar" /&gt;</ph> 클래스의 새 인스턴스를 초기화합니다.</target>       </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.DictationGrammar.#ctor">
          <source>The default dictation grammar emulates standard dictation practices, including punctuation.</source>
          <target state="translated">기본 받아쓰기 문법 문장 부호를 포함 하 여 표준 받아쓰기 사례를 에뮬레이션 합니다.</target>       </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.DictationGrammar.#ctor">
          <source>It does not support the spelling of a word.</source>
          <target state="translated">단어의 맞춤법을 지원 하지는 않습니다.</target>       </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.DictationGrammar.#ctor(System.String)">
          <source>An XML-compliant Universal Resource Identifier (URI) that specifies the dictation grammar, either <bpt id="p1">&lt;c&gt;</bpt>grammar:dictation<ept id="p1">&lt;/c&gt;</ept> or <bpt id="p2">&lt;c&gt;</bpt>grammar:dictation#spelling<ept id="p2">&lt;/c&gt;</ept>.</source>
          <target state="translated">받아쓰기 문법인 <bpt id="p1">&lt;c&gt;</bpt>grammar:dictation<ept id="p1">&lt;/c&gt;</ept> 또는 <bpt id="p2">&lt;c&gt;</bpt>grammar:dictation#spelling<ept id="p2">&lt;/c&gt;</ept>을 지정하는 XML 규격 URI(Universal Resource Identifier)입니다.</target>       </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.DictationGrammar.#ctor(System.String)">
          <source>Initializes a new instance of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.DictationGrammar" /&gt;</ph> class with a specific dictation grammar.</source>
          <target state="translated">지정된 받아쓰기 문법을 사용하여 <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.DictationGrammar" /&gt;</ph> 클래스의 새 인스턴스를 초기화합니다.</target>       </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.DictationGrammar.#ctor(System.String)">
          <source>The Speech platform uses a specialized URI syntax to define the custom dictation grammar.</source>
          <target state="translated">음성 플랫폼 특별 한 URI 구문을 사용 하 여 사용자 지정 받아쓰기 문법을 정의 합니다.</target>       </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.DictationGrammar.#ctor(System.String)">
          <source>The value <ph id="ph1">`grammar:dictation`</ph> indicates the default dictation grammar.</source>
          <target state="translated">값 <ph id="ph1">`grammar:dictation`</ph> 기본 받아쓰기 문법을 나타냅니다.</target>       </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.DictationGrammar.#ctor(System.String)">
          <source>The value <ph id="ph1">`grammar:dictation#spelling`</ph> indicates the spelling dictation grammar.</source>
          <target state="translated">값 <ph id="ph1">`grammar:dictation#spelling`</ph> 맞춤법 받아쓰기 문법을 나타냅니다.</target>       </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)">
          <source>Text that indicates the start of a dictation context.</source>
          <target state="translated">받아쓰기 컨텍스트의 시작을 나타내는 텍스트입니다.</target>       </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)">
          <source>Text that indicates the end of a dictation context.</source>
          <target state="translated">받아쓰기 컨텍스트의 끝을 나타내는 텍스트입니다.</target>       </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)">
          <source>Adds a context to a dictation grammar that has been loaded by a <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> or a <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> object.</source>
          <target state="translated"><ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> 또는 <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /&gt;</ph> 개체에 의해 로드된 받아쓰기 문법에 컨텍스트를 추가합니다.</target>       </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)">
          <source>By default, the dictation grammar does not make use of specific words or word order to identify and interpret audio input.</source>
          <target state="translated">기본적으로 받아쓰기 문법 미치지 않으며 특정 단어의 사용 또는 단어 순서를 식별 하 여 오디오 입력을 해석 합니다.</target>       </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)">
          <source>When a context is added to a dictation grammar, the recognition engine uses the <ph id="ph1">`precedingText`</ph> and <ph id="ph2">`subsequentText`</ph> to identify when to interpret speech as dictation.</source>
          <target state="translated">인식 엔진에 사용 하 여 컨텍스트를 받아쓰기 문법에 추가 되는 <ph id="ph1">`precedingText`</ph> 및 <ph id="ph2">`subsequentText`</ph> 음성 받아쓰기로 해석 하는 시기를 식별 하 합니다.</target>       </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)">
          <source>A dictation grammar must be loaded by a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> object before you can use <ph id="ph3">&lt;xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A&gt;</ph> to add a context.</source>
          <target state="translated">받아쓰기 문법을 로드 해야는 <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> 또는 <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> 개체를 사용 하려면 먼저 <ph id="ph3">&lt;xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A&gt;</ph> 컨텍스트를 추가 하려면.</target>       </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)">
          <source>The following table describes how the recognition engine uses the two parameters to determine when to use the dictation grammar.</source>
          <target state="translated">다음 표에서 인식 엔진 받아쓰기 문법을 사용 하는 시기를 결정 하는 두 개의 매개 변수를 사용 하는 방법을 설명 합니다.</target>       </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)">
          <source>Description</source>
          <target state="translated">설명</target>       </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)">
          <source>not <ph id="ph1">`null`</ph></source>
          <target state="translated"><ph id="ph1">`null`</ph> 아님</target>       </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)">
          <source>not <ph id="ph1">`null`</ph></source>
          <target state="translated"><ph id="ph1">`null`</ph> 아님</target>       </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)">
          <source>The recognition engine uses the terms to bracket possible candidate phrases.</source>
          <target state="translated">인식 엔진 용어를 사용 하 여 가능한 후보 구 묶습니다.</target>       </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)">
          <source>not <ph id="ph1">`null`</ph></source>
          <target state="translated"><ph id="ph1">`null`</ph> 아님</target>       </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)">
          <source>The recognition engine uses the <ph id="ph1">`subsequentText`</ph> to finish dictation.</source>
          <target state="translated">인식 엔진 사용 하 여는 <ph id="ph1">`subsequentText`</ph> 받아쓰기 완료 합니다.</target>       </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)">
          <source>not <ph id="ph1">`null`</ph></source>
          <target state="translated"><ph id="ph1">`null`</ph> 아님</target>       </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)">
          <source>The recognition engine uses the <ph id="ph1">`precedingText`</ph> to start dictation.</source>
          <target state="translated">인식 엔진 사용 하 여는 <ph id="ph1">`precedingText`</ph> 받아쓰기를 시작 합니다.</target>       </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)">
          <source>The recognition engine does not use a context when using the dictation grammar.</source>
          <target state="translated">인식 엔진 받아쓰기 문법을 사용 하는 경우 컨텍스트를 사용 하지 않습니다.</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>